{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a691707-be18-4f3b-ab8f-d9f8ef789915",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "import sys, os\n",
    "\n",
    "# Setting the root directory as a string.\n",
    "root = r'<ROOT LOCATION OF REPORT FOLDER>'\n",
    "\n",
    "# Combining the root directory with the target directory to create the full path\n",
    "path = os.path.join(root, \"targetdirectory\")\n",
    "\n",
    "# Create empty lists to store the full file paths and file names\n",
    "fullFilePaths = []\n",
    "fileNames = []\n",
    "\n",
    "# Walk through all the subdirectories and files within the root directory\n",
    "for path, subdirs, files in os.walk(root):\n",
    "    # Loop through all the files in each subdirectory\n",
    "    for name in files:\n",
    "        # Create the full file path by joining the path and file name\n",
    "        fullFilePaths.append(os.path.join(path, name))\n",
    "\n",
    "# The final output will be the full file paths of all the files within the specified root directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd5eec30-223e-4304-aad2-2d612564c5f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the pandas library to work with dataframes\n",
    "import pandas as pd\n",
    "\n",
    "# Specify the filepath of the GRI excel file using a raw string to prevent backslash escaping\n",
    "griFullFileName = r'<GRI FILE LOCATION>'\n",
    "\n",
    "# Open the GRI excel file using pd.ExcelFile() and save it to the variable xls\n",
    "xls = pd.ExcelFile(griFullFileName)\n",
    "\n",
    "# Create an empty dictionary to store the dataframes\n",
    "fullGRI = {}\n",
    "\n",
    "# Loop through each sheet in the Excel file except for the \"Overview\" sheet\n",
    "# and read the sheet into a dataframe using pd.read_excel()\n",
    "# Add each dataframe to the fullGRI dictionary with the sheet name as the key\n",
    "for sheet_name in xls.sheet_names[1:21]:\n",
    "    fullGRI[sheet_name] = pd.read_excel(griFullFileName, sheet_name = sheet_name, header=1)\n",
    "\n",
    "# Read the \"Overview\" sheet into a dataframe separately and add it to the fullGRI dictionary with the key \"Overview\"\n",
    "fullGRI[\"Overview\"] = pd.read_excel(griFullFileName, sheet_name = \"Overview\")\n",
    "\n",
    "# Create a new dataframe named total_df by concatenating all dataframes in the fullGRI dictionary except for the \"Overview\" sheet\n",
    "# Set ignore_index argument to True to create a new index for the concatenated dataframe\n",
    "total_df = fullGRI[\"1999\"]\n",
    "for sheet_name in xls.sheet_names[2:21]:\n",
    "    total_df = pd.concat([total_df, fullGRI[sheet_name]], ignore_index=True)\n",
    "\n",
    "# Modify the 'Name' column in total_df by removing all spaces using the str.replace() method\n",
    "total_df['Name'] = total_df['Name'].str.replace(' ', '')\n",
    "\n",
    "# The resulting concatenated dataframe total_df contains all GRI data from 1999 to 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad1bc23c-364e-4ab0-8195-f129dfb8dd4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the regular expressions library to work with patterns\n",
    "import re\n",
    "\n",
    "# Create an empty dataframe with two columns named \"Organization\" and \"Year\"\n",
    "df = pd.DataFrame(columns=[\"Organization\", \"Year\"])\n",
    "\n",
    "# Loop through each file path in the fullFilePaths list\n",
    "for filePath in fullFilePaths:\n",
    "    # Extract the file name without extension from the file path\n",
    "    fileName = os.path.splitext(os.path.split(filePath)[1])[0]\n",
    "\n",
    "    # Create a list of two items by splitting the file name using \"_\" as a separator\n",
    "    # The first item is the organization name, and the second item is the year\n",
    "    row = [fileName.split(\"_\")[0], fileName.split(\"_\")[-1]]\n",
    "\n",
    "    # Add the row to the dataframe at the next available index using df.loc[]\n",
    "    df.loc[len(df)] = row\n",
    "\n",
    "# Convert the \"Year\" column to numeric values using pd.to_numeric()\n",
    "df['Year'] = pd.to_numeric(df['Year'])\n",
    "\n",
    "# The resulting dataframe df contains information about the PDF files, including the organization name and year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7765dbea-0b3d-413b-b28b-a96479ef7a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# INPUT: GRI DATAFRAME and PDF FILES DATAFRAME\n",
    "import numpy as np\n",
    "\n",
    "# merge the two dataframes based on 'Organization' and 'Year' columns\n",
    "almost_df = pd.merge(df, total_df,  how='left', left_on=['Organization','Year'], right_on = ['Name','Publication Year'])\n",
    "\n",
    "# drop the 'Name' and 'Publication Year' columns from the merged dataframe\n",
    "final_df = almost_df.drop(['Name','Publication Year'], axis=1)\n",
    "\n",
    "# drop duplicate rows based on 'Organization' and 'Year' columns\n",
    "final_df = final_df.drop_duplicates(subset=['Organization', 'Year']).reset_index(drop=True)\n",
    "\n",
    "# OUTPUT: ONE FULL MERGED DATAFRAME WITH ALL THE PDF FILES AND GRI INFORMATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee2ec643-cc5a-4322-8756-cc6ab1b649ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code reads several CSV files and creates pandas dataframes from them. \n",
    "# Each dataframe contains specific columns of interest from their respective CSV files. \n",
    "# The file paths of the CSV files are hardcoded into the code.\n",
    "df_keywords = pd.read_csv(r'<FILE LOCATION OF KEYWORD RESEARCH>')[[\"Greenhouse_Gas_Emissions\", \"Diversity\", \"Employee_Health_Safety\", \"Customer_Welfare\"]]\n",
    "df_language = pd.read_csv(r'<FILE LOCATION OF LANGUAGE RESEARCH>')[[\"Language\"]]\n",
    "df_sentiment = pd.read_csv(r'<FILE LOCATION OF SENTIMENT RESEARCH>')[[\"neg\", \"neu\", \"pos\", \"compound\", \"Overall sentiment\"]]\n",
    "df_topicModelling = pd.read_csv(r'<FILE LOCATION OF TOPIC MODELLING RESEARCH>')[[\"Topics\"]]\n",
    "df_wordCount = pd.read_csv(r'<FILE LOCATION OF WORDCOUNT RESEARCH>')[[\"WordCount\"]]\n",
    "# The resulting dataframes will be used later in the program, to combine the data from all of the dataframes into a single dataframe that contains all of the desired information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "735fd290-45ac-45ea-9f73-ddfe263d3385",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here all the different dataframes are combined onto eachother\n",
    "final_df = final_df.join(df_keywords).join(df_language).join(df_sentiment).join(df_topicModelling).join(df_wordCount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5c7c38b2-61ea-44e2-8ed9-95bb06d68ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the file location to which the final dataframe will be exported\n",
    "file_location = r'<EXPORT FILE LOCATION>'\n",
    "\n",
    "# Export the final dataframe to the defined file location as a CSV file, without the index column\n",
    "final_df.to_csv(file_location, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
